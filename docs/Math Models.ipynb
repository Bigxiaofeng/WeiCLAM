{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Математические модели и формулы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>TODO:</font> Заменить скобки на нормальные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обозначения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $G = (V,E) $ — граф\n",
    "* $A \\in \\mathbb{R}^{N\\times N}$ — матрица смежности \n",
    "* $F \\in \\mathbb{R}^{N\\times K}$ — матрица принадлежности к сообществам\n",
    "* $K$ — количество сообществ\n",
    "* $C$ — множество сообществ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigCLAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/BigCLAM_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предположения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Каждая вершина $v$ относится к сообществу $c$ с некоторой силой $F_{vc} >0$. \n",
    "* Вероятность появления ребра $(u,v)$, при условии, что вершины $u,v$ находятся в одном сообществе $c$ есть \n",
    "\n",
    "$$P((u,v) | c)=1 - \\exp(-F_{uc} F_{vc}).$$\n",
    "\n",
    "* Каждое сообщество $c$ генерирует ребра независимо друг от друга, а значит, что вероятность появления ребра \n",
    "\n",
    "$$P(u,v)=1 - \\exp(-\\sum_{c\\in C} F_{uc} F_{vc}) = 1 - \\exp( - F_{u} F_{v}^T),$$\n",
    "\n",
    "$$F = \\{F_u\\} = \\{F_{uc}\\} \\in \\mathbb{R}^{N \\times K}. $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вероятностная интерпретация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Каждые две вершины $u, v$ взаимодействуют с некоторой силой $X_{uv}$. Чем больше сила, тем больше вероятность $p(u,v)$ появления ребра.\n",
    "* Сила взаимодействия вершин $u, v$ определяется сообществами. Каждое сообщество $c$, в которое входит одновременно 2 вершины дает свой аддитивный вклад в силу их взаимодействия $X_{uv}^{(c)}$.\n",
    "* **Предполагаем**, что $X_{uv}^{(c)} \\sim \\mathrm{Pois}(F_{uc} \\cdot F_{vc})$, где $F_{vc}>0$ сила взаимодействия вершины $v$ и сообщества $c$. Значит, что \n",
    "\n",
    "$$X_{uv} \\sim \\mathrm{Pois}(\\sum_{c} F_{uc} \\cdot F_{vc}) = \\mathrm{Pois}(F_{u} \\cdot F_{v}^T).$$\n",
    "\n",
    "* **Предполагаем**, что ребро появляется, если $X_{uv} > 0$. Т.е.\n",
    "\n",
    "$$p(u,v) = \\mathbb{P}(X_{uv} > 0) = 1 - \\exp( - F_{u} F_{v}^T).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\varepsilon$-сообщество\n",
    "Предполагаем, что все вершины относятся к большому $\\varepsilon$-сообществу с малой силой ($\\approx 10^{-6}$) (т.к. иначе, вершины, не входящие в одно сообщество не могут быть соединены ребром). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используется метод максимизации правдоподобия.\n",
    "\n",
    "$$l(F) = log(\\mathbb{P}(A|F))$$\n",
    "\n",
    "$$l(F) = \\sum_{(u,v)\\in E} \\log(1 - \\exp( - F_{u} F_{v}^T)) - \\sum_{(u,v) \\notin E} F_u F_v^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Вопрос:</font> не портят ли наши регуляризации выпуклости?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Схема оптимизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая задача является частным случаем NMF (Non-negative matrix factorization):\n",
    "Ищем такую низкоранговую матрицу $F\\in \\mathbb{R}^{N \\times K}$, что она наилучшим образом приближает матрицу $A$ в смысле правдоподобия (на самом деле $l_2$-норма плохо подходит для восстановления бинарных матриц): \n",
    "\n",
    "$$ \\hat{F} = \\arg \\min_{F \\ge 0} D(A, f(FF^T)),$$\n",
    "\n",
    "$$\\text{гдe}\\quad D = -l(F), \\quad f(x) = 1-\\exp(-x).$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оптимизации используется блочный координатный спуск с методом проекции градиента на каждом шаге.\n",
    "Фиксируем $F_v$, оптимизируем по $F_u$, $u \\ne v$. Задача становится выпуклой.\n",
    "\n",
    "$$\\forall u: \\quad \\arg\\max_{F_u \\ge 0} l(F_u), $$\n",
    "\n",
    "$$l(F_u) = \\sum_{v \\in \\mathcal{N}(u)} \\log(1-\\exp(-F_u F_v^T)) - \\sum_{v \\notin \\mathcal{N}(u)} F_u F_v^T $$\n",
    "\n",
    "$\\mathcal{N}(u)$ — соседи вершины u.\n",
    "\n",
    "$$\\nabla l(F_u) = \\sum_{v \\in \\mathcal{N}(u)} F_u \\dfrac{\\exp(-F_u F_v^T)}{1-exp(-F_u F_v^T)} - \\sum_{v \\notin \\mathcal{N}(u)} F_v^T. $$\n",
    "\n",
    "Основная сложность формулы (линейная по размеру графа) во втором слагаемом. Заметим, что \n",
    "\n",
    "$$\\sum_{v \\notin \\mathcal{N}(u)} F_v^T = \\sum_v{F_v} - F_u - \\sum_{v\\in \\mathcal{N}(u)} F_v.$$ \n",
    "\n",
    "Получаем сложность одной итерации $O(\\mathcal{N}(u))$.\n",
    "\n",
    "Для подбора градиентного шага используем backtracking line search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Восстановление структуры сообществ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы восстановить исходную структуру сообществ $C$ сравним значение матрицы $F$ с порогом $\\delta$. Обозначим за $\\varepsilon$ вероятность появления ребра в графе (если бы все ребра появлялись равномерно): $\\varepsilon = \\dfrac{2|V|}{|E|\\cdot (|E|-1)}$. Возьмем $\\delta$ так, чтобы две вершины принадлежали одному сообществу, если модельная вероятность появления ребра между ними выше чем $\\varepsilon$:\n",
    "\n",
    "$$\\varepsilon \\le 1-\\exp(-\\delta^2)$$\n",
    "\n",
    "$$\\delta = \\sqrt{-\\log(1-\\varepsilon)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>TODO:</font> Заполнить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WeiCLAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое простое изменение BigCLAM для обработки взвешенных ребер:\n",
    "\n",
    "$$l(F) = \\sum_{(u,v)\\in E} \\log(1 - \\exp\\left( - \\dfrac{F_{u} F_{v}^T}{w_{uv}}\\right) - \\sum_{(u,v) \\notin E} \\dfrac{F_{u} F_{v}^T}{w_{uv}}.$$\n",
    "\n",
    "Тем самым, мы получаем, что чем больше вес $w_{uv}$, тем больше должно быть значение сил $F_u$ и $F_v$, которые его объясняют.\n",
    "\n",
    "Т.е. Предположение, что вероятность появления ребра $(u,v)$, при условии, что вершины $u,v$ находятся в одном сообществе $c$ есть \n",
    "\n",
    "$$P((u,v) | c)=1 - \\exp\\left( -F_{uc} F_{vc} \\right).$$\n",
    "\n",
    "Заменяется на предположение, что вероятность появления ребра $(u,v)$ **с весом $w_{uv}$**, при условии, что вершины $u,v$ находятся в одном сообществе $c$ есть \n",
    "\n",
    "$$P((u,v) | c, w_{uv})=1 - \\exp\\left(-\\dfrac{F_{uc} F_{vc}}{w_{uv}}\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>TODO:</font> Дописать.\n",
    "\n",
    "Красивая вероятностная интерпретация: $$X_{uv}^{(c)} \\sim \\mathrm{Pois}\\left(\\dfrac{F_{uc} \\cdot F_{vc}}{w_{uv}}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тесты подтверждают работоспособность модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GammaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Совершенно другая вероятностная модель к описанию наблюдаемых графов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предпосылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тут еще есть про \"правильный\" аналог непрерывного распределения Пуассона: http://ac.inf.elte.hu/Vol_039_2013/137_39.pdf\n",
    "надо попробовать потренировать ее тоже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы посмотрим на первоначальную модель, то увидим, что в ней есть скрытые переменные $X_{uv}$, которые распределены по Пуассону. Данное распределение является дискретным, а веса на ребрах -- непрерывные. \n",
    "\n",
    "Самое главное свойство, которые использовались в выводе — мультипликативность. Так что в качестве непрерывного аналога распределения Пуассона можно взять Гамма распределение, сумма которых (с одинаковым коэффициентом масштаба) не выводит из класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предположения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Вероятность появления ребра с весом $w_{uv}$, при условии, что вершины принадлежат сообществу $c$\n",
    "\n",
    "$$p\\left(w_{uv} | c\\right) \\sim \\mathrm{\\Gamma}\\left(k=F_u F_v^T, \\theta=1\\right).$$\n",
    "\n",
    "* Каждое сообщество $c$ генерирует ребра независимо друг от друга, а значит, что вес ребра\n",
    "\n",
    "$$w_{uv} = \\sum_{c} w_{uv}^c \\sim \\mathrm{\\Gamma}\\left(\\sum_c F_{uc} F_{vc} + 1, 1\\right) = \\mathrm{\\Gamma}\\left(F_u F_v^T + 1, 1\\right).$$\n",
    "\n",
    "Берем $+ 1$ для того, чтобы не сталкиваться с распределениями с бесконечной плотностью в нуле. В вероятностном смысле это безусловная (от сообществ) вероятность появления ребра в графе.\n",
    "\n",
    "\n",
    "Для простоты везде далее будем опускать параметр $\\theta$.\n",
    "\n",
    "Обозначим $K_{uv} = F_u F_v^T + 1.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$l\\left(F\\right) = log\\left(\\mathbb{P}\\left(A|F\\right)\\right)$$\n",
    "\n",
    "$$ l\\left(F\\right) = \\sum_{w_uv} \\log p(w_{uv}) $$\n",
    "\n",
    "$$ l\\left(F\\right)= \\sum_{w_{uv}}\\left[-\\log\\mathrm{\\Gamma}\\left(K_{uv}\\right) - K_{uv}\\log\\theta + (K_{uv} - 1)\\cdot\\log w_{uv} - \\dfrac{w_{uv}}{\\theta}\\right] $$\n",
    "\n",
    "$$ l\\left(F\\right)= \\sum_{w_{uv}}\\left[-\\log\\mathrm{\\Gamma}\\left(K_{uv}\\right) + (K_{uv} - 1)\\cdot\\log w_{uv} - w_{uv}\\right] $$\n",
    "\n",
    "$$ l\\left(F\\right)= \\sum_{w_{uv}}\\left[-\\log\\mathrm{\\Gamma}\\left( F_u F_v^T + 1 \\right) + F_u F_v^T \\cdot\\log w_{uv} - w_{uv}\\right] \\rightarrow \\max_{F\\ge 1}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Схема оптимизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы посчитать градиент, нам понадобится дигамма функция:\n",
    "\n",
    "$$\\Psi(x) = \\dfrac{\\mathrm{d}}{\\mathrm{d}x} \\log\\left(\\mathrm\\Gamma(x)\\right)$$\n",
    "\n",
    "$$\\dfrac{\\mathrm{d}l(F)}{\\mathrm{d}F_u} = - \\sum_v F_v \\Psi\\left(F_u F_v^T + 1\\right) + F_v \\cdot  \\left( \\log\\theta - \\log w_{uv}\\right)$$\n",
    "\n",
    "$$\\dfrac{\\mathrm{d}l(F)}{\\mathrm{d}F_u} = - \\sum_v F_v \\Psi\\left(F_u F_v^T + 1\\right) - F_v \\log w_{uv}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Схема оптимизации используется та же самая, что и в BigCLAM.\n",
    "\n",
    "Ко всем весам прибавляется небольшое $\\varepsilon$, чтобы избежать нулей под логарифмом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для ускорения вычисления можно отдельно хранить $\\log w_{uv}$ и $\\Psi\\left(F_u F_v^T + 1\\right)$, каждый раз обновляя 1 строчку и 1 столбец. Тем не менее, т.к. сумма взвешенная, провести такой трюк как в BigCLAM не получится. Для каждого шага, для каждого $F_u$ придется пересчитывать сумму целиком. Получается линейная сложность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>TODO:</font> Оптимизировать схему оптимизации в коде."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>TODO:</font> Понять, что подход из BigClam обобщается и на этот случай, записать как, а еще можно и теоремы передоказать (например, конкретно для этой модели)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
